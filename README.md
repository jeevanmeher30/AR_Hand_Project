Real-Time "Hollow Purple" AR Hand Tracker
This Python project uses your webcam to create a real-time augmented reality experience inspired by the "Hollow Purple" technique from Jujutsu Kaisen. It tracks your hand movements and allows you to generate and control a powerful energy ball with a specific hand gesture.

Features
Real-Time Hand Tracking: Utilizes Google's MediaPipe library to accurately track 21 key points of your hand in the live webcam feed.

Advanced Gesture Recognition: Detects a specific hand sign (index and middle fingers up, others curled) to activate the main effect.

"Red & Blue" Fusion Sequence: When the gesture is made, a red and a blue orb appear and converge at your fingertip, fusing to create the final purple energy ball, mimicking the anime.

Dynamic Energy Ball: The final purple orb is visually complex, featuring a smooth gradient, crackling lightning, an unstable aura, and a space-bending gravitational lensing effect.

Projectile Casting: Once the energy ball is fully charged, a quick forward "push" motion with your hand will launch it across the screen as a projectile.

How to Run
Prerequisites
Python 3.7 or newer

A webcam

1. Setup a Virtual Environment (Recommended)
Open your terminal or command prompt, navigate to the project folder, and run:

# Create the virtual environment
python -m venv venv

# Activate it
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

2. Install Dependencies
With your virtual environment active, install the required libraries:

pip install opencv-python mediapipe numpy

3. Run the Script
Execute the main Python file from your terminal:

python main.py

A window with your webcam feed should appear. Make the hand gesture in front of the camera to activate the effect. Press 'q' to quit.

Key Concepts Explained
Gesture Detection: The program doesn't "see" a gesture. Instead, it constantly checks the relative positions of your finger landmarks. For example, to detect a "straight" finger, it checks if the y-coordinate of the fingertip is less than (higher on the screen than) the y-coordinate of the middle joint (the PIP knuckle). The is_specific_gesture function combines several of these simple checks to recognize the complex sign.

State Machine: The energy ball's behavior is controlled by a simple state machine with three states:

idle: The default state. Nothing is happening.

charging: Triggered when you make the gesture. This state runs the red and blue orb convergence animation.

active: Triggered after the red and blue orbs fuse. This state grows the final purple energy ball.
This system ensures the effects happen in the correct sequence.

Procedural Effects: The visual effects like the gradient, lightning, and distortion are procedural, meaning they are generated by code in real-time. The lightning, for instance, is created with a recursive algorithm that repeatedly splits a line and displaces its midpoint, creating a natural, jagged look that is different every frame.
